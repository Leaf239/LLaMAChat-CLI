import os
import subprocess
import sys
import requests
from pathlib import Path

def install_requirements():
    subprocess.check_call([sys.executable, "-m", "pip", "install", "-r", "requirements.txt"])

def download_model():
    model_url = "https://huggingface.co/bartowski/Llama-3.2-3B-Instruct-GGUF/resolve/main/Llama-3.2-3B-Instruct-Q4_K_M.gguf"
    models_dir = Path("models")
    models_dir.mkdir(exist_ok=True)
    model_path = models_dir / "Llama-3.2-3B-Instruct-Q4_K_M.gguf"

    if model_path.exists():
        print("âœ… ëª¨ë¸ ì´ë¯¸ ìˆìŒ. ë‹¤ìš´ë¡œë“œ ìŠ¤í‚µí•¨.")
        return

    print("â¬‡ï¸ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì¤‘... (ì¢€ ê±¸ë¦´ ìˆ˜ ìˆìŒ)")
    with requests.get(model_url, stream=True) as r:
        r.raise_for_status()
        with open(model_path, "wb") as f:
            for chunk in r.iter_content(chunk_size=8192):
                if chunk:
                    f.write(chunk)
    print("âœ… ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ!")

if __name__ == "__main__":
    print("ğŸ”§ ì˜ì¡´ì„± ì„¤ì¹˜ ì¤‘...")
    install_requirements()

    print("ğŸ“¦ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì¤‘...")
    download_model()

    print("ğŸš€ ì…‹ì—… ì™„ë£Œ! ì´ì œ main.py ì‹¤í–‰ ã„±ã„±")
